{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "Итак, давайте применим новые знания для решения следующей задачи: имеется список отзывов о ресторанах. Необходимо разделить их на положительные и отрицательные. В случае невозможности классификации ставить 'undef'.\n",
    "\n",
    "Файл с отзывами texts_opinions.txt\n",
    "\n",
    "Файл с отзывами имеет кодировку UTF-8 и может некорректно отображаться при открытии в браузере.\n",
    "\n",
    "Для классификации для каждого отзыва будем использовать следующий алгоритм:\n",
    "\n",
    "1. Предварительно составляем список основ слов, которые характеризуют положительные и отрицательные отзывы. Используем SnowballStemmer библиотеки NLTK (можно было использовать Pymystem, сейчас для простоты используем NLTK).\n",
    "2. Разбиваем текст отзыва на отдельные слова (здесь нам заранее придется удалить все знаки препинания).\n",
    "3. Заменяем каждое слово на его основу с помощью SnowballStemmer библиотеки NLTK.\n",
    "4. Ищем основу каждого слова отзыва среди основ слов из пункта 1. Считаем каких слов получилось больше - из списка \"положительных\" или \"отрицательных\" слов. Если таких слов в отзыве не нашлось или их число совпало, то возвращаем 'undef'.\n",
    "\n",
    "После классификации отзывов мы можем сверить наш результат с \"правильной\" классификацией texts_ratings.txt, которую выставляли сами пользователи, когда писали эти отзывы.\n",
    "\n",
    "Файл texts_ratings.txt\n",
    "\n",
    "Несколько замечаний:\n",
    "\n",
    "1. Сейчас мы не рассматриваем качество и правдивость составленных отзывов. Наша задача - научиться пользоваться инструментами для подобных задач.\n",
    "2. Существует множество алгоритмов решения этой задачи, в том числе с помощью машинного обучения. Абсолютное большинство из них начинаются также как и наш - со стемминга или лемматизации исходных текстов.\n",
    "3. Аналогичный подход может сильно помочь вам в задачах фильтрации данных по словам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбивка на слова\n",
    "Итак, сначала составим список основ слов, которые характерны для положительных и отрицательных отзывов. Чтобы не учитывать их многочисленные формы используем стеммер NLTK. Например, найдем основу слова \"благодарны\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from yaml import load\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 благодарн\n",
      "благодарн\n",
      "благодарн\n",
      "благодарн\n"
     ]
    }
   ],
   "source": [
    "snowball_stemmer = SnowballStemmer(\"russian\")\n",
    "print('1', snowball_stemmer.stem('благодарны'))\n",
    "\n",
    "for word in ['благодарность', 'благодарностью', 'благодарны']:\n",
    "    print(snowball_stemmer.stem( word ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./module16_files/params.yaml', encoding='utf-8') as f:\n",
    "    params = load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала необходимо удалить из текста знаки препинания, чтобы его можно легко было разбить на слова через пробел. Воспользуемся методом translate. Метод берет список знаков препинания symbols и применяет к ним метод translate. При этом заменяя их на пробелы. Для этого мы заводим строку spaces из такого же количества пробелов, что и symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_punctuation(text):\n",
    "    \"\"\"Удаление знаком пунктуации из текста text\"\"\"\n",
    "\n",
    "    return re.sub(r'[^\\w\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Просто шикарный клуб! Ходили с другом на \"Animal Джаz\"! Остались очень довольны, атмосфера очень уютная, дружелюбная, есть второй этаж, бар'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Просто шикарный клуб Ходили с другом на Animal Джаz Остались очень довольны атмосфера очень уютная дружелюбная есть второй этаж бар'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_punctuation(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение классификатора\n",
    "Чтобы получить список слов, основы которых входят в список \"положительных\" наборов слов, достаточно использовать list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_punctuation = clear_punctuation(text)\n",
    "\n",
    "positive_words_list = [x for x in text_no_punctuation.split(' ') \n",
    "                       if snowball_stemmer.stem(x) in params['positive']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['довольны']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом тексте оказалось только одно \"положительное\" слово. \n",
    "# Есть чем расширить наши списки для улучшения модели классификации:\n",
    "\n",
    "print(positive_words_list)\n",
    "# ['довольны']\n",
    "\n",
    "# Количество слов в таком списке считаем с помощью функции len:\n",
    "\n",
    "positive_words_count = len(positive_words_list)\n",
    "\n",
    "positive_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(text):\n",
    "\n",
    "    \"\"\"Классификация отзыва text на 'positive', 'negative' и 'undef' по совпадающим основам слов из params.yaml\"\"\"\n",
    "\n",
    "    text = clear_punctuation(text)\n",
    "    positive_words_count = len([x for x in text.split() if snowball_stemmer.stem(x) in params['positive']])\n",
    "    negative_words_count = len([x for x in text.split() if snowball_stemmer.stem(x) in params['negative']])\n",
    "    if positive_words_count > negative_words_count:\n",
    "        return 'positive'\n",
    "    elif positive_words_count < negative_words_count:\n",
    "        return 'negative'\n",
    "    return 'undef'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем как работает (на очевидных примерах):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'Ужасное место. Сотрудники клуба от них в восторге! А культурным людям тут не место.'\n",
    "\n",
    "classifier(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогоним наш файл с отзывами через классификатор. В этом скрипте мы используем одни и те же файлы для чтения и записи. В таких случаях рекомендуется \"закрывать\" их с помощью метода close, чтобы при следующем открытии не возникало проблем и каждый раз не придумывать новые названия переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './module16_files/'\n",
    "\n",
    "f = open(os.path.join(path, 'texts_opinions.txt'), encoding = 'utf-8')\n",
    "f_classified = open(os.path.join(path, 'texts_classified.txt'), 'w', encoding = 'utf-8')\n",
    "\n",
    "for line in f:\n",
    "    line = line.strip()    \n",
    "    f_classified.write('{}\\n'.format(classifier(line)))\n",
    "\n",
    "f.close()\n",
    "f_classified.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка точности модели\n",
    "Теперь давайте сравним оценки нашего классификатора с реальными оценками пользователей в файле texts_ratings.txt. Будем пользовать следующими правилами:\n",
    "\n",
    "1. Не учитываем отзывы, которые мы не смогли классифицировать (значение 'undef').\n",
    "2. Для определенных типов отзывов (positive и negative) считаем их общее количество в переменной total_defined_ratings.\n",
    "3. Если оценка отзыва в файлах совпала, то увеличиваем переменную right_classifications на 1.\n",
    "4. В конце алгоритма выводим долю верно угаданных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верно классифицированных отзывов: 77%\n"
     ]
    }
   ],
   "source": [
    "f_classified = open(os.path.join(path, 'texts_classified.txt'), encoding = 'utf-8')\n",
    "f_ratings = open(os.path.join(path, 'texts_ratings.txt'), encoding = 'utf-8')\n",
    "\n",
    "classified_list = [line.strip() for line in f_classified]\n",
    "ratings_list = [line.strip() for line in f_ratings]\n",
    "right_classifications = 0\n",
    "total_defined_ratings = 0\n",
    "\n",
    "for i in range(len(classified_list)):\n",
    "    if classified_list[i] != 'undef':\n",
    "        total_defined_ratings += 1\n",
    "        if classified_list[i] == ratings_list[i]:\n",
    "            right_classifications += 1\n",
    "\n",
    "print('Доля верно классифицированных отзывов: {:.0%}'.format(right_classifications / total_defined_ratings))\n",
    "\n",
    "f_classified.close()\n",
    "f_ratings.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, при первой самой простой модели мы получили точность классификации 77%. Конечно, это без учета того, что часть отзыва мы не классифицировали. Но долю неопределенных отзывов можно уменьшить, добавив в наш словарь больше \"положительных\" и \"отрицательных\" слов.\n",
    "\n",
    "Попробуйте улучшить классификатор, добавив в params.yaml больше слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
